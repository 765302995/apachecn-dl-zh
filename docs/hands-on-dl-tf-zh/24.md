# TensorFlowLearn

正如 Scikit-Learn 是传统机器学习算法的便捷接口一样，[`tf.contrib.learn`](https://github.com/tensorflow/tensorflow/tree/master/tensorflow/contrib/learn/python/learn)（以前称为`skflow`），它是构建和训练 DNN 的简化接口。 现在，随 TensorFlow 的每次安装免费提供！

即使您不喜欢该语法，也值得将 TensorFlow Learn 作为 TensorFlow 的高级 API。 这是因为它是当前唯一受官方支持的版本。 但是，您应该知道，有许多替代的高级 API 可能具有更直观的接口。 如果有兴趣，请参阅 [Keras](https://keras.io/)，`tf.slim`（包含在 TF 中）或 [TFLearn](http://tflearn.org/)。为了了解有关 TensorFlow-Slim 的更多信息，请参阅[此链接](https://github.com/tensorflow/tensorflow/tree/master/tensorflow/contrib/slim)。

## 设置

要开始使用 TensorFlow Learn，您只需导入它即可。 我们还将导入`estimators`函数，这将帮助我们制作常规模型：

```py
# TF made EZ
import tensorflow.contrib.learn as learn
from tensorflow.contrib.learn.python.learn.estimators import estimator
```

我们还希望导入一些用于基本操作的库-抓取 NumPy，math 和 Matplotlib（可选）。 这里值得注意的是`sklearn`，这是一个通用的机器学习库，它试图简化模型的创建，训练和使用。 我们主要将其用于方便的指标，但是您会发现它具有与 Learn 类似的主接口：

```py
# Some basics
import numpy as np
import math
import matplotlib.pyplot as plt
plt.ion()

# Learn more sklearn
# scikit-learn.org
import sklearn
from sklearn import metrics
```

接下来，我们将读取一些数据进行处理。 由于您熟悉字体分类问题，因此让我们继续对其建模。 为了重现性，您可以使用自己喜欢的数字为 NumPy 播种：

```py
# Seed the data
np.random.seed(42)

# Load data
data = np.load('data_with_labels.npz')
train = data['arr_0']/255.
labels = data['arr_1']
```

对于本练习，将您的数据分为训练和验证集； `np.random.permutation`对于为您的输入数据生成随机顺序很有用，所以让我们像在以前的模块中那样使用它：

```py
# Split data into training and validation
indices = np.random.permutation(train.shape[0])
valid_cnt = int(train.shape[0] * 0.1)
test_idx, training_idx = indices[:valid_cnt],\
                         indices[valid_cnt:]
test, train = train[test_idx,:],\
              train[training_idx,:]
test_labels, train_labels = labels[test_idx],\
                        labels[training_idx]
```

在这里，`tf.contrib.learn`可以对其接收的数据类型有所变幻。 为了发挥出色，我们需要重铸数据。 图像输入将是`np.float32`，而不是默认的 64 位。 同样，我们的标签将是`np.int32`而不是`np.uint8`，即使这只会占用更多内存：

```py
train = np.array(train,dtype=np.float32)
test = np.array(test,dtype=np.float32)
train_labels = np.array(train_labels,dtype=np.int32)
test_labels = np.array(test_labels,dtype=np.int32)
```

## 逻辑回归

让我们做一个简单的逻辑回归示例。 这将非常迅速，并显示`learn`如何使简单的模型变得异常简单。 首先，我们必须创建模型期望输入的变量列表。 您可能希望可以使用一个简单的参数来设置它，但实际上是这个不直观的`learn.infer_real_valued_columns_from_input`函数。 基本上，如果将输入数据提供给该函数，它将推断出您拥有多少个特征列以及其应处于的形状。在我们的线性模型中，我们希望将图像展平为一维，因此我们对其执行整形推断函数时：

```py
# Convert features to learn style
feature_columns = learn.infer_real_valued_columns_from_input(train.reshape([-1,36*36]))
```

现在创建一个名为`classifier`的新变量，并为其分配`estimator.SKCompat`结构。 这是一个 Scikit-Learn 兼容性层，允许您在 TensorFlow 模型中使用某些 Scikit-Learn 模块。

无论如何，这仅仅是敷料，真正创建模型的是`learn.LinearClassifier`。 这样就建立了模型，但是没有训练。 因此，它只需要几个参数。 首先是那个时髦的`feature_columns`对象，只是让您的模型知道期望输入什么。 第二个也是最后一个必需的参数是它的反函数，模型应具有多少个输出值？ 我们有五种字体，因此设置`n_classes = 5`。 这就是整个模型规格！

```py
# Logistic Regression
classifier = estimator.SKCompat(learn.LinearClassifier(
            feature_columns = feature_columns,
            n_classes=5))
```

要进行训练，只需要一行。 调用`classifier.fit`并输入数据（当然是经过调整的形状），输出标签（请注意，这些标签不必是一字不漏的格式）以及其他一些参数。 `steps`参数确定模型将查看多少批次，即优化算法要采取的步骤。 `batch_size`参数通常是优化步骤中要使用的数据点数。 因此，您可以将步数乘以批次大小除以训练集中的数据点数来计算周期数。 这似乎有点违反直觉，但至少是一个快速的说明，您可以轻松编写帮助函数以在步骤和周期之间进行转换：

```py
# One line training
# steps is number of total batches
# steps*batch_size/len(train) = num_epochs
classifier.fit(train.reshape([-1,36*36]),
               train_labels,
               steps=1024,
               batch_size=32)
```

为了评估我们的模型，我们将照常使用`sklearn`的`metrics`。 但是，基本学习模型预测的输出现在是字典，其中包含预先计算的类标签以及概率和对数。 要提取类标签，请使用键`classes`：

```py
# sklearn compatible accuracy
test_probs = classifier.predict(test.reshape([-1,36*36]))
sklearn.metrics.accuracy_score(test_labels,
        test_probs['classes'])
```