# DNN

尽管有更好的方法来实现纯线性模型，但 TensorFlow 和`learn`真正的亮点在于简化具有不同层数的 DNN。

我们将使用相同的输入特征，但现在我们将构建一个具有两个隐藏层的 DNN，首先是`10`神经元，然后是`5`。 创建此模型仅需一行 Python 代码； 这再简单不过了。

规格类似于我们的线性模型。 我们仍然需要`SKCompat`，但现在是`learn.DNNClassifier`。 对于参数，还有一个额外的要求：每个隐藏层上的神经元数量，以列表的形式传递。 这个简单的论点真正抓住了 DNN 模型的本质，使深度学习的力量触手可及。

也有一些可选的参数，但是我们只提及`optimizer`。 这样，您就可以在不同的常见优化器例程之间进行选择，例如随机梯度下降（SGD）或 Adam。 很方便！

```py
# Dense neural net
classifier = estimator.SKCompat(learn.DNNClassifier(
            feature_columns = feature_columns,
            hidden_units=[10,5],
            n_classes=5,
            optimizer='Adam'))
```

训练和评估与线性模型完全一样。 仅出于演示目的，我们还可以查看此模型创建的混淆矩阵。 请注意，我们训练不多，因此该模型可能无法与使用纯 TensorFlow 的早期作品竞争：

```py
# Same training call
classifier.fit(train.reshape([-1,36*36]),
               train_labels,
               steps=1024,
               batch_size=32)

# simple accuracy
test_probs = classifier.predict(test.reshape([-1,36*36]))
sklearn.metrics.accuracy_score(test_labels,
        test_probs['classes'])

# confusion is easy
train_probs = classifier.predict(train.reshape([-1,36*36]))
conf = metrics.confusion_matrix(train_labels,
        train_probs['classes'])
print(conf)
```

## TFLearn 中的卷积神经网络（CNN）

CNN 支持一些最成功的机器学习模型，因此我们希望`learn`支持它们。 实际上，该库支持使用任意 TensorFlow 代码！ 您会发现这是一种祝福和诅咒。 拥有任意可用的代码意味着您可以使用`learn`来执行几乎可以使用纯 TensorFlow 进行的所有操作，从而提供最大的灵活性。 但是通用接口往往会使代码更难以读写。

如果您发现自己在`learn`中使用接口使某些复杂的模型起作用，那么可能是时候使用纯 TensorFlow 或切换到另一个 API 了。

为了证明这种通用性，我们将构建一个简单的 CNN 来解决字体分类问题。 它将具有一个带有四个过滤器的卷积层，然后将其展平为具有五个神经元的隐藏密集层，最后以密集连接的输出逻辑回归结束。

首先，让我们再进行几个导入。 我们想要访问通用的 TensorFlow，但是我们还需要`layers`模块以`learn`期望的方式调用 TensorFlow `layers`：

```py
# Access general TF functions
import tensorflow as tf
import tensorflow.contrib.layers as layers
```

通用接口迫使我们编写为模型创建操作的函数。 您可能会发现这很乏味，但这就是灵活性的代价。

用三个参数启动一个名为`conv_learn`的新函数。 `X`将作为输入数据，`y`将作为输出标签（尚未进行一次热编码），`mode`确定您是训练还是预测。 请注意，您永远不会直接与此特征交互； 您只需将其传递给需要这些参数的构造函数。 因此，如果您想改变层的数量或类型，则需要编写一个新的模型函数（或另一个会生成这种模型函数的函数）：

```py
def conv_learn(X, y, mode):
```

由于这是卷积模型，因此我们需要确保数据格式正确。 特别是，这意味着将输入重塑为不仅具有正确的二维形状（36x36），而且具有 1 个颜色通道（最后一个尺寸）。 这是 TensorFlow 计算图的一部分，因此我们使用`tf.reshape`而不是`np.reshape`。 同样，由于这是通用图，因此我们希望将输出进行一次热编码，`tf.one_hot`提供了该功能。 请注意，我们必须描述有多少类（`5`），应设置的值（`1`）和未设置的值（`0`）：

```py
    # Ensure our images are 2d 
    X = tf.reshape(X, [-1, 36, 36, 1])
    # We'll need these in one-hot format
    y = tf.one_hot(tf.cast(y, tf.int32), 5, 1, 0)
```

现在，真正的乐趣开始了。 为了指定卷积层，让我们初始化一个新的作用域`conv_layer`。 这只会确保我们不会破坏任何变量。 `layers.convolutional`提供了基本的机制。 它接受我们的输入（一个 TensorFlow 张量），多个输出（实际上是内核或过滤器的数量）以及内核的大小，这里是 5x5 的窗口。 对于激活函数，让我们使用整流线性，可以从主 TensorFlow 模块调用它。 这给了我们基本的卷积输出`h1`。

实际上，最大池化的发生与常规 TensorFlow 中的发生完全相同，既不容易也不难。 具有通常的内核大小和步幅的`tf.nn.max_pool`函数可以正常工作。 保存到`p1`中：

```py
    # conv layer will compute 4 kernels for each 5x5 patch
    with tf.variable_scope('conv_layer'):
        # 5x5 convolution, pad with zeros on edges
        h1 = layers.convolution2d(X, num_outputs=4,
                kernel_size=[5, 5], 
                activation_fn=tf.nn.relu)
        # 2x2 Max pooling, no padding on edges
        p1 = tf.nn.max_pool(h1, ksize=[1, 2, 2, 1],
                strides=[1, 2, 2, 1], padding='VALID')
```

现在，要在此时展平张量，我们需要计算将要成为一维张量的元素数量。 一种方法是将所有尺寸值（`batch_size`除外，它占据第一个位置）相乘。 此特定操作可以在计算图之外进行，因此我们使用`np.product`。 一旦提供了总大小，我们就可以将其传递给`tf.reshape`以重新划分图中的中间张量：

```py
    # Need to flatten conv output for use in dense layer
    p1_size = np.product(
              [s.value for s in p1.get_shape()[1:]])
    p1f = tf.reshape(p1, [-1, p1_size ])
```

现在是时候建立紧密连接的层了。 `layers`模块再次出现，这一次具有`fully_connected`函数（致密层的另一个名称）。 这需要上一层，神经元的数量和激活函数，它们又由通用 TensorFlow 提供。

为了演示的目的，我们也在此处添加一个 dropout 对象。 `layers.dropout`提供了接口。 不出所料，它需要上一层以及保持给定节点输出的概率。 但是它也需要我们传递给原始`conv_learn`函数的`mode`参数。 所有这些复杂的接口只不过是在训练期间丢弃节点。 如果您能解决这个问题，那么我们几乎可以遍历整个模型！

```py
     # densely connected layer with 32 neurons and dropout
     h_fc1 = layers.fully_connected(p1f,
             5,
             activation_fn=tf.nn.relu)
     drop = layers.dropout(h_fc1, keep_prob=0.5,
     is_training=mode == tf.contrib.learn.ModeKeys.TRAIN)
```

现在有一些坏消息。 我们需要手动写出最终的线性模型，损失函数和优化参数。 这可能会因版本而异，因为在某些情况下，以前对用户来说更容易，但对后端的维护则更困难。 但是，让我们坚持下去； 确实不是很繁琐。

另一个`layers.fully_connected`层创建最终的逻辑回归。 请注意，此处的激活应为`None`，因为它是线性的。 处理方程逻辑方面的是损失函数。 值得庆幸的是，TensorFlow 提供了`softmax_cross_entropy`函数，因此我们无需手动将其写出。 给定输入，输出和损失函数，我们可以应用优化例程。 同样，`layers.optimize_loss`以及相关函数可以最大程度地减少痛苦。 将您的损失节点，优化器（作为字符串）和学习率传递给它。 此外，为其提供此`get_global_step()`参数，以确保优化程序正确处理衰减。

最后，我们的函数需要返回一些东西。 第一，它应该报告预测的类别。 接下来，它必须自己提供损失节点输出。 最后，训练节点必须可用于外部例程以实际执行所有操作：

```py
    logits = layers.fully_connected(drop, 5, activation_fn=None)
    loss = tf.losses.softmax_cross_entropy(y, logits)
    # Setup the training function manually
    train_op = layers.optimize_loss(
        loss,
        tf.contrib.framework.get_global_step(),
        optimizer='Adam',
        learning_rate=0.01)
    return tf.argmax(logits, 1), loss, train_op
```

虽然指定模型可能很麻烦，但使用它就像以前一样容易。 现在，使用最通用的例程`learn.Estimator`，并将模型函数传递给`model_fn`。 并且不要忘记`SKCompat`！

训练的工作原理与以前完全相同，只是请注意，我们不需要在此处重塑输入内容，因为这是在函数内部处理的。

要使用模型进行预测，您可以简单地调用`classifier.predict`，但是请注意，您会获得函数返回的第一个参数作为输出。 我们选择返回该类，但也可以从`softmax`函数中返回概率。 这就是`tf.contrib.learn`模型的基础！

```py
# Use generic estimator with our function
classifier = estimator.SKCompat(
         learn.Estimator(
         model_fn=conv_learn))

classifier.fit(train,train_labels,
                steps=1024,
                batch_size=32)

# simple accuracy
metrics.accuracy_score(test_labels,classifier.predict(test))
```

## 提取权重

虽然训练和预测是模型的核心用途，但也必须研究模型的内部也很重要。 不幸的是，此 API 使得提取参数权重变得困难。 值得庆幸的是，本节提供了一些文献记载较弱的功能的简单示例，以使权重从`tf.contrib.learn`模型中消失。

为了拉出模型的权重，我们确实需要从基础 TensorFlow 计算图中的某些点获取值。 TensorFlow 提供了许多方法来执行此操作，但是第一个问题只是弄清楚您感兴趣的变量被称为什么。

可以使用`learn`图中的变量名列表，但该变量名已隐藏在`_estimator`隐藏属性下。 调用`classifier._estimator.get_variable_names()`将返回您各种名称的字符串列表。 其中许多将是无趣的，例如`OptimizeLoss`条目。 在我们的情况下，我们正在寻找`conv_layer`和`fully_connected`元素：

```py
# See layer names
print(classifier._estimator.get_variable_names())
['OptimizeLoss/beta1_power',
 'OptimizeLoss/beta2_power',
 'OptimizeLoss/conv_layer/Conv/biases/Adam',
 'OptimizeLoss/conv_layer/Conv/biases/Adam_1',
 'OptimizeLoss/conv_layer/Conv/weights/Adam',
 'OptimizeLoss/conv_layer/Conv/weights/Adam_1',
 'OptimizeLoss/fully_connected/biases/Adam',
 'OptimizeLoss/fully_connected/biases/Adam_1',
 'OptimizeLoss/fully_connected/weights/Adam',
 'OptimizeLoss/fully_connected/weights/Adam_1',
 'OptimizeLoss/fully_connected_1/biases/Adam',
 'OptimizeLoss/fully_connected_1/biases/Adam_1',
 'OptimizeLoss/fully_connected_1/weights/Adam',
 'OptimizeLoss/fully_connected_1/weights/Adam_1',
 'OptimizeLoss/learning_rate',
 'conv_layer/Conv/biases',
 'conv_layer/Conv/weights',
 'fully_connected/biases',
 'fully_connected/weights',
 'fully_connected_1/biases',
 'fully_connected_1/weights',
 'global_step']
```

找出哪个条目是您要查找的层可能是一个挑战。 在这里，`conv_layer`显然来自我们的卷积层。 但是，您看到两个`fully_connected`元素，一个是展平时的密集层，另一个是输出权重。 事实证明，它们是按指定的顺序命名的。 我们首先创建了密集的隐藏层，所以它获得了基本的`fully_connected`名称，而输出层位于最后，因此在其上面加上了`_1`。 如果不确定，可以随时查看权重数组的形状，具体取决于模型的形状。

要真正发挥作用，这是另一个不可思议的要求。 这次，`classifier._estimator.get_variable_value`（带有变量名字符串）提供了具有相关权重的 NumPy 数组。 试用卷积权重和偏差以及密集层：

```py
# Convolutional Layer Weights
print(classifier._estimator.get_variable_value(
        'conv_layer/Conv/weights'))
print(classifier._estimator.get_variable_value(
        'conv_layer/Conv/biases'))

# Dense Layer
print(classifier._estimator.get_variable_value(
        'fully_connected/weights'))

# Logistic weights
print(classifier._estimator.get_variable_value(
        'fully_connected_1/weights'))
```

现在，掌握了如何在`tf.contrib.learn`神经网络内部进行交流的深奥知识，您将可以使用此高级 API 拥有更多的能力。 尽管在许多情况下很方便，但在其他情况下却很麻烦。 永远不要害怕暂停并考虑切换到另一个库； 为正确的机器学习工作使用正确的机器学习工具。