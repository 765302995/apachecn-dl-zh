# 总结

在本章中，我们实现了一些称为自编码器的优化网络。自编码器基本上是数据压缩网络模型。它用于将给定输入编码为较小维度的表示，然后可以使用解码器从编码版本重建输入。我们实现的所有自编码器都包含编码和解码部分。

我们还看到了如何通过在网络训练期间引入噪声和构建去噪自编码器来提高自编码器的表现。最后，我们应用[第 4 章](../Text/ch04.html "Chapter 4. Convolutional Neural Networks")中介绍的 CNN 概念，卷积神经网络上的 TensorFlow 和卷积自编码器的实现。

即使隐藏单元的数量很大，我们仍然可以通过在网络上施加其他约束来使用自编码器发现数据集的有趣和隐藏结构。换句话说，如果我们对隐藏单元施加稀疏约束，那么即使隐藏单元的数量很大，自编码器仍将在数据中发现有趣的结构。为了证明这一论点，我们看到了一个真实的例子，即信用卡欺诈分析，我们成功应用了自编码器。

循环神经网络（RNN）是一类人工神经网络，其中单元之间的连接形成有向循环。 RNN 利用过去的信息，如时间序列预测。这样，他们就可以对具有高时间依赖性的数据进行预测。这创建了网络的内部状态，允许它展示动态时间行为。

在下一章中，我们将研究 RNN。我们将首先描述这些网络的基本原理，然后我们将实现这些架构的一些有趣示例。