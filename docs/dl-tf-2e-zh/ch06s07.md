# 总结

LSTM 网络配备了特殊的隐藏单元，称为存储单元，其目的是长时间记住先前的输入。这些单元在每个时刻采用先前状态和网络的当前输入作为输入。通过将它们与内存的当前内容相结合，并通过其他单元的门控机制决定保留什么以及从内存中删除什么，LSTM 已被证明是非常有用的并且是学习长期依赖性的有效方式。

在本章中，我们讨论了 RNN。我们看到了如何使用具有高时间依赖性的数据进行预测。我们看到了如何开发几种真实的预测模型，使用 RNN 和不同的架构变体使预测分析更容易。我们从 RNN 的理论背景开始。

然后我们看了几个例子，展示了一种实现图像分类预测模型，电影和产品情感分析以及 NLP 垃圾邮件预测的系统方法。然后我们看到了如何开发时间序列数据的预测模型。最后，我们看到了 RNN 用于人类活动识别的更高级应用，我们观察到分类准确率约为 87％。

DNN 以统一的方式构造，使得在网络的每一层，数千个相同的人工神经元执行相同的计算。因此，DNN 的架构非常适合 GPU 可以有效执行的计算类型。 GPU 具有优于 CPU 的额外优势;这些包括具有更多计算单元并具有更高的带宽用于存储器检索。

此外，在许多需要大量计算工作的深度学习应用中，可以利用 GPU 的图形特定功能来进一步加速计算。在下一章中，我们将看到如何使训练更快，更准确，甚至在节点之间分配。