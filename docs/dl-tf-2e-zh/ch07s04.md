# 分布式 TensorFlow 设置

在本节中，我们将探索 TensorFlow 中的计算可以分布的机制。运行分布式 TensorFlow 的第一步是使用`tf.train.ClusterSpec`指定集群的架构：

```py
import tensorflow as tf

cluster = tf.train.ClusterSpec({"ps": ["localhost:2222"],\
                                "worker": ["localhost:2223",\
                                           "localhost:2224"]})
```

节点通常分为两个作业：主机变量的参数服务器（`ps`）和执行大量计算的工作器。在上面的代码中，我们有一个参数服务器和两个 worker，以及每个节点的 IP 地址和端口。

然后我们必须为之前定义的每个参数服务器和 worker 构建一个`tf.train.Server`：

```py
ps = tf.train.Server(cluster, job_name="ps", task_index=0)

worker0 = tf.train.Server(cluster,\
                          job_name="worker", task_index=0)
worker1 = tf.train.Server(cluster,\
                          job_name="worker", task_index=1)
```

`tf.train.Server`对象包含一组本地设备，一组与`tf.train.ClusterSpec`中其他任务的连接，以及一个可以使用它们执行分布式计算的`tf.Session`。创建它是为了允许设备之间的连接。

接下来，我们使用以下命令将模型变量分配给 worker：

```py
tf.device :

with tf.device("/job:ps/task:0"):
    a = tf.constant(3.0, dtype=tf.float32)
    b = tf.constant(4.0)
```

将这些指令复制到名为`main.py`的文件中。

在两个单独的文件`worker0.py`和`worker1.py`中，我们必须定义工作器。在`worker0.py`中，将两个变量`a`和`b`相乘并打印出结果：

```py
import tensorflow as tf
from main import *

with tf.Session(worker0.target) as sess:
    init = tf.global_variables_initializer()
    add_node = tf.multiply(a,b)
    sess.run(init)
    print(sess.run(add_node))
```

在`worker1.py`中，首先更改`a`的值，然后将两个变量`a`和`b`相乘：

```py
import tensorflow as tf
from main import *

with tf.Session(worker1.target) as sess:
    init = tf.global_variables_initializer()
    a = tf.constant(10.0, dtype=tf.float32)
    add_node = tf.multiply(a,b)
    sess.run(init)
    a = add_node
    print(sess.run(add_node))
```

要执行此示例，首先从命令提示符运行`main.py`文件。

你应该得到这样的结果：

```py
>python main.py

Found device 0 with properties:
name: GeForce 840M
major: 5 minor: 0 memoryClockRate (GHz) 1.124
pciBusID 0000:08:00.0
Total memory: 2.00GiB
Free memory: 1.66GiB

    Started server with target: grpc://localhost:2222
```

然后我们可以运行工作器：

```py
> python worker0.py

Found device 0 with properties:
name: GeForce 840M
major: 5 minor: 0 memoryClockRate (GHz) 1.124
pciBusID 0000:08:00.0
Total memory: 2.00GiB
Free memory: 1.66GiB

    Start master session 83740f48d039c97d with config:
    12.0
> python worker1.py

Found device 0 with properties:
name: GeForce 840M
major: 5 minor: 0 memoryClockRate (GHz) 1.124
pciBusID 0000:08:00.0
Total memory: 2.00GiB
Free memory: 1.66GiB

    Start master session 3465f63a4d9feb85 with config:
    40.0
```