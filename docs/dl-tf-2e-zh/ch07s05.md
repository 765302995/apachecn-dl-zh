# 总结

在本章中，我们快速了解了与优化 DNN 计算相关的两个基本主题。

第一个主题解释了如何使用 GPU 和 TensorFlow 来实现 DNN。它们以非常统一的方式构造，使得在网络的每一层，数千个相同的人工神经元执行相同的计算。因此，DNN 的架构非常适合 GPU 可以有效执行的计算类型。

第二个主题介绍了分布式计算。这最初用于执行非常复杂的计算，这些计算无法由单个机器完成。同样，在面对如此大的挑战时，通过在不同节点之间拆分此任务来快速分析大量数据似乎是最佳策略。

同时，可以使用分布式计算来利用 DL 问题。 DL 计算可以分为多个活动（任务）;他们每个人都将获得一小部分数据，并返回一个结果，该结果必须与其他活动提供的结果重新组合。或者，在大多数复杂情况下，可以为每台机器分配不同的计算算法。

最后，在最后一个例子中，我们展示了如何分配 TensorFlow 中的计算。