# Keras

Keras 是一个用 Python 编写的开源神经网络库。它专注于最小化，模块化和可扩展性，旨在实现 DNN 的快速实验。

该库的主要作者和维护者是名为 FrançoisChollet 的 Google 工程师，该库是项目 ONEIROS（开放式神经电子智能机器人操作系统）研究工作的一部分。

Keras 是按照以下设计原则开发的：

*   模块化：模型被理解为独立，完全可配置的模块序列或图，可以通过尽可能少的限制插入到一起。神经层，成本函数，优化器，初始化方案和激活函数都是独立的模块，可以组合起来创建新模型。
*   极简主义：每个模块必须简短（几行代码）并且简单。在肮脏的读取之上，源代码应该是透明的。
*   可扩展性：新模块易于添加（如新类和函数），现有模块提供了基于新模块的示例。能够轻松创建新模块可以实现完全表现力，使 Keras 适合高级研究。

Keras 既可以作为 TensorFlow API 在嵌入式版本中使用，也可以作为库使用：

*   tf.keras 来自[此链接](https://www.tensorflow.org/api_docs/python/tf/keras)
*   Keras v 2.1.4（更新和安装指南请参见[此链接](https://keras.io)）

    在以下部分中，我们将了解如何使用第一个和第二个实现。

## Keras 编程模型

Keras 的核心数据结构是一个模型，它是一种组织层的方法。有两种类型的模型：

*   顺序：这只是用于实现简单模型的线性层叠
*   函数式 API：用于更复杂的架构，例如具有多个输出和有向无环图的模型

### 顺序模型

在本节中，我们将快速通过向您展示代码来解释顺序模型的工作原理。让我们首先使用 TensorFlow API 导入和构建 Keras `Sequential` 模型：

```py
import tensorflow as tf
from tensorflow.python.keras.models import Sequential
model = Sequential()
```

一旦我们定义了模型，我们就可以添加一个或多个层。堆叠操作由`add()`语句提供：

```py
from keras.layers import Dense, Activation
```

例如，让我们添加第一个完全连接的神经网络层和激活函数：

```py
model.add(Dense(output_dim=64, input_dim=100))
model.add(Activation("relu"))
```

然后我们添加第二个`softmax`层：

```py
model.add(Dense(output_dim=10))
model.add(Activation("softmax"))
```

如果模型看起来很好，我们必须`compile()`模型，指定损失函数和要使用的优化器：

```py
model.compile(loss='categorical_crossentropy',\
              optimizer='sgd',\
              metrics=['accuracy'])
```

我们现在可以配置我们的优化器。 Keras 尝试使编程变得相当简单，允许用户在需要时完全控制。

编译完成后，模型必须符合以下数据：

```py
model.fit(X_train, Y_train, nb_epoch=5, batch_size=32)
```

或者，我们可以手动将批次提供给我们的模型：

```py
model.train_on_batch(X_batch, Y_batch)
```

一旦训练完成，我们就可以使用我们的模型对新数据进行预测：

```py
classes = model.predict_classes(X_test, batch_size=32)
proba = model.predict_proba(X_test, batch_size=32)
```

#### 电影评论的情感分类

在这个例子中，我们将 Keras 序列模型应用于情感分析问题。情感分析是破译书面或口头文本中包含的观点的行为。这种技术的主要目的是识别词汇表达的情感（或极性），这可能具有中性，正面或负面的含义。我们想要解决的问题是 IMDB 电影评论情感分类问题：每个电影评论是一个可变的单词序列，每个电影评论的情感（正面或负面）必须分类。

问题非常复杂，因为序列的长度可能不同，并且包含大量的输入符号词汇。该解决方案要求模型学习输入序列中符号之间的长期依赖关系。

IMDB 数据集包含 25,000 个极地电影评论（好的或坏的）用于训练，并且相同的数量再次用于测试。这些数据由斯坦福大学的研究人员收集，并用于 2011 年的一篇论文中，其中 50-50 分的数据被用于训练和测试。在本文中，实现了 88.89％的准确率。

一旦我们定义了问题，我们就可以开发一个顺序 LSTM 模型来对电影评论的情感进行分类。我们可以快速开发用于 IMDB 问题的 LSTM 并获得良好的准确率。让我们首先导入此模型所需的类和函数，并将随机数生成器初始化为常量值，以确保我们可以轻松地重现结果。

在此示例中，我们在 TensorFlow API 中使用嵌入式 Keras：

```py
import numpy
from tensorflow.python.keras.models import Sequential
from tensorflow.python.keras.datasets import imdb
from tensorflow.python.keras.layers import Dense
from tensorflow.python.keras.layers import LSTM
from tensorflow.python.keras.layers import Embedding
from tensorflow.python.keras.preprocessing import sequence
numpy.random.seed(7)
```

我们加载 IMDB 数据集。我们将数据集限制为前 5,000 个单词。我们还将数据集分为训练（50％）和测试（50％）集。

Keras 提供对 IMDB 数据集的内置访问。 `imdb.load_data()`函数允许您以准备好在神经网络和 DL 模型中使用的格式加载数据集。单词已被整数替换，这些整数表示数据集中每个单词的有序频率。因此，每个评论中的句子包括一系列整数。

这是代码：

```py
top_words = 5000
(X_train, y_train), (X_test, y_test) = \
                          imdb.load_data(num_words=top_words)
```

接下来，我们需要截断并填充输入序列，以便它们具有相同的建模长度。该模型将学习不携带信息的零值，因此序列在内容方面的长度不同，但是向量需要在 Keras 中计算相同的长度。每个评论中的序列长度各不相同，因此我们将每个评论限制为`500`单词，截断长评论并用零值填充较短评论：

让我们来看看：

```py
max_review_length = 500
X_train = sequence.pad_sequences\
                  (X_train, maxlen=max_review_length)
X_test = sequence.pad_sequences\
                  (X_test, maxlen=max_review_length)
```

我们现在可以定义，编译和调整我们的 LSTM 模型。

要解决情感分类问题，我们将使用单词嵌入技术。它包括在连续向量空间中表示单词，该向量空间是语义相似的单词被映射到相邻点的区域。单词嵌入基于分布式假设，该假设指出出现在给定上下文中的单词必须具有相同的语义含义。然后将每个电影评论映射到真实的向量域，其中在意义方面的单词之间的相似性转换为向量空间中的接近度。 Keras 提供了一种通过使用嵌入层将单词的正整数表示转换为单词嵌入的便捷方式。

在这里，我们定义嵌入向量和模型的长度：

```py
embedding_vector_length = 32
model = Sequential()
```

第一层是嵌入层。它使用 32 个长度向量来表示每个单词：

```py
model.add(Embedding(top_words, \
                    embedding_vector_length,\
                      input_length=max_review_length))
```

下一层是具有`100`存储单元的 LSTM 层。最后，因为这是一个分类问题，我们使用具有单个神经元的密集输出层和`sigmoid`激活函数来预测问题中的类（好的和坏的）：

```py
model.add(LSTM(100))
model.add(Dense(1, activation='sigmoid'))
```

因为它是二元分类问题，我们使用`binary_crossentropy`作为损失函数，而这里使用的优化器是`adam`优化算法（我们在之前的  TensorFlow 实现中遇到过它）：

```py
model.compile(loss='binary_crossentropy',\
              optimizer='adam',\
                metrics=['accuracy'])
print(model.summary())
```

我们只适合三个周期，因为模型很快就会适应。批量大小为 64 的评论用于分隔权重更新：

```py
model.fit(X_train, y_train, \
           validation_data=(X_test, y_test),\
              num_epochs=3, \
                batch_size=64)
```

然后，我们估计模型在看不见的评论中的表现：

```py
scores = model.evaluate(X_test, y_test, verbose=0)
print("Accuracy: %.2f%%" % (scores[1]*100))
```

运行此示例将生成以下输出：

```py
Epoch 1/3
16750/16750 [==============================] - 107s - loss: 0.5570 - acc: 0.7149
Epoch 2/3
16750/16750 [==============================] - 107s - loss: 0.3530 - acc: 0.8577
Epoch 3/3
16750/16750 [==============================] - 107s - loss: 0.2559 - acc: 0.9019
Accuracy: 86.79%
```

您可以看到，这个简单的 LSTM 几乎没有调整，可以在 IMDB 问题上获得最接近最先进的结果。重要的是，这是一个模板，您可以使用该模板将 LSTM 网络应用于您自己的序列分类问题。

### 函数式 API

为了构建复杂的网络，我们将在这里描述的函数式方法非常有用。如第 4 章，卷积神经网络上的 TensorFlow 所示，最流行的神经网络（AlexNET，VGG 等）由一个或多个重复多次的神经迷你网络组成。函数式 API 包括将神经网络视为我们可以多次调用的函数。这种方法在计算上是有利的，因为为了构建神经网络，即使是复杂的神经网络，也只需要几行代码。

在以下示例中，我们使用来自[此链接](https://keras.io)的 Keras v2.1.4 。

让我们看看它是如何工作的。首先，您需要导入`Model`模块：

```py
from keras.models import Model
```

首先要做的是指定模型的输入。让我们使用`Input()`函数声明一个 28×28×1 的张量：

```py
from keras.layers import Input
digit_input = Input(shape=(28, 28,1))
```

这是顺序模型和函数式 API 之间的显着差异之一。因此，使用`Conv2D`和`MaxPooling2D` API，我们构建卷积层：

```py
x = Conv2D(64, (3, 3))(digit_input)
x = Conv2D(64, (3, 3))(x)
x = MaxPooling2D((2, 2))(x)
out = Flatten()(x)
```

请注意，变量`x`指定应用层的变量。最后，我们通过指定输入和输出来定义模型：

```py
vision_model = Model(digit_input, out)
```

当然，我们还需要使用`fit`和`compile`方法指定损失，优化器等，就像我们对顺序模型一样。

#### SqueezeNet

在这个例子中，我们引入了一个名为 SqueezeNet 的小型 CNN 架构，它在 ImageNet 上实现了 AlexNet 级精度，参数减少了 50 倍。这个架构的灵感来自 GoogleNet 的初始模块，发表在论文中：SqueezeNet：AlexNet 级准确率，参数减少 50 倍，&lt; 1MB 模型，[可从此链接下载](http://arxiv.org/pdf/1602.07360v2.pdf)。

SqueezeNet 背后的想法是减少使用压缩方案处理的参数数量。此策略使用较少的过滤器减少参数数量。这是通过将挤压层送入它们所称的扩展层来完成的。这两层组成了所谓的 Fire Module，如下图所示：

![SqueezeNet](img/B09678_08_02.jpg)

图 2：SqueezeNet 消防模块

`fire_module`由 1×1 卷积滤波器组成，然后是 ReLU 操作：

```py
x = Convolution2D(squeeze,(1,1),padding='valid', name='fire2/squeeze1x1')(x)
x = Activation('relu', name='fire2/relu_squeeze1x1')(x)
```

`expand`部分有两部分：`left`和`right`。

`left`部分使用 1×1 卷积，称为扩展 1×1：

```py
left = Conv2D(expand, (1, 1), padding='valid', name=s_id + exp1x1)(x)
left = Activation('relu', name=s_id + relu + exp1x1)(left)
```

`right`部分使用 3×3 卷积，称为`expand3x3`。这两个部分后面都是 ReLU 层：

```py
right = Conv2D(expand, (3, 3), padding='same', name=s_id + exp3x3)(x)
right = Activation('relu', name=s_id + relu + exp3x3)(right)
```

消防模块的最终输出是左右连接：

```py
x = concatenate([left, right], axis=channel_axis, name=s_id + 'concat')
```

然后，重复使用`fire_module`构建完整的网络，如下所示：

```py
x = Convolution2D(64,(3,3),strides=(2,2), padding='valid',\ 
                                             name='conv1')(img_input)
x = Activation('relu', name='relu_conv1')(x)
x = MaxPooling2D(pool_size=(3, 3), strides=(2, 2), name='pool1')(x)

x = fire_module(x, fire_id=2, squeeze=16, expand=64)
x = fire_module(x, fire_id=3, squeeze=16, expand=64)
x = MaxPooling2D(pool_size=(3, 3), strides=(2, 2), name='pool3')(x)

x = fire_module(x, fire_id=4, squeeze=32, expand=128)
x = fire_module(x, fire_id=5, squeeze=32, expand=128)
x = MaxPooling2D(pool_size=(3, 3), strides=(2, 2), name='pool5')(x)

x = fire_module(x, fire_id=6, squeeze=48, expand=192)
x = fire_module(x, fire_id=7, squeeze=48, expand=192)
x = fire_module(x, fire_id=8, squeeze=64, expand=256)
x = fire_module(x, fire_id=9, squeeze=64, expand=256)
x = Dropout(0.5, name='drop9')(x)

x = Convolution2D(classes, (1, 1), padding='valid', name='conv10')(x)
x = Activation('relu', name='relu_conv10')(x)
x = GlobalAveragePooling2D()(x)
x = Activation('softmax', name='loss')(x)
model = Model(inputs, x, name='squeezenet')
```

下图显示了 SqueezeNet 架构：

![SqueezeNet](img/B09678_08_03.jpg)

图 3：SqueezeNet 架构

您可以从下面的链接 SqueezeNet 的 Keras 执行  （在`squeezenet.py`文件）：HTG3] https://github.com/rcmalli/keras-squeezenet [HTG4。

然后我们在以下`squeeze_test.jpg`（227×227）图像上测试模型：

![SqueezeNet](img/B09678_08_04.jpg)

图 4：SqueezeNet 测试图像

我们只需使用以下几行代码即可：

```py
import os
import numpy as np
import squeezenet as sq
from keras.applications.imagenet_utils import preprocess_input
from keras.applications.imagenet_utils import preprocess_input, decode_predictions
from keras.preprocessing import image

model = sq.SqueezeNet()
img = image.load_img('squeeze_test.jpg', target_size=(227, 227))
x = image.img_to_array(img)
x = np.expand_dims(x, axis=0)
x = preprocess_input(x)

preds = model.predict(x)
print('Predicted:', decode_predictions(preds))
```

如您所见，结果非常有趣：

```py
Predicted: [[('n02504013', 'Indian_elephant', 0.64139527), ('n02504458', 'African_elephant', 0.22846894), ('n01871265', 'tusker', 0.12922771), ('n02397096', 'warthog', 0.00037213496), ('n02408429', 'water_buffalo', 0.00032306617)]]
```