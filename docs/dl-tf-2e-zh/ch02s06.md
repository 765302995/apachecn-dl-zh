# TensorFlow 中的数据模型

TensorFlow 中的数据模型由张量表示。在不使用复杂的数学定义的情况下，我们可以说张量（在 TensorFlow 中）识别多维数值数组。我们将在下一小节中看到有关张量的更多细节。

## 张量

让我们看一下来自[维基百科：张量](https://en.wikipedia.org/wiki/Tensor)的形式定义：

> “张量是描述几何向量，标量和其他张量之间线性关系的几何对象。这种关系的基本例子包括点积，叉积和线性映射。几何向量，通常用于物理和工程应用，以及标量他们自己也是张量。“

该数据结构的特征在于三个参数：秩，形状和类型，如下图所示：

![Tensor](img/B09698_02_06.jpg)

图 6：张量只是具有形状，阶数和类型的几何对象，用于保存多维数组

因此，张量可以被认为是指定具有任意数量的索引的元素的矩阵的推广。张量的语法与嵌套向量大致相同。

### 提示

张量只定义此值的类型以及在会话期间应计算此值的方法。因此，它们不代表或保留操作产生的任何价值。

有些人喜欢比较 NumPy 和 TensorFlow。然而，实际上，TensorFlow 和 NumPy 在两者都是 N-d 数组库的意义上非常相似！

嗯，NumPy 确实有 n 维数组支持，但它不提供方法来创建张量函数并自动计算导数（并且它没有 GPU 支持）。下图是 NumPy 和 TensorFlow 的简短一对一比较：

![Tensor](img/B09698_02_14.jpg)

图 7：NumPy 与 TensorFlow：一对一比较

现在让我们看一下在 TensorFlow 图之前创建张量的替代方法（我们将在后面看到其他的进给机制）：

```py
>>> X = [[2.0, 4.0],
        [6.0, 8.0]] # X is a list of lists
>>> Y = np.array([[2.0, 4.0],
                 [6.0, 6.0]], dtype=np.float32)#Y is a Numpy array
>>> Z = tf.constant([[2.0, 4.0],
                    [6.0, 8.0]]) # Z is a tensor

```

这里，`X`是列表，`Y`是来自 NumPy 库的 n 维数组，`Z`是 TensorFlow 张量对象。现在让我们看看他们的类型：

```py
>>> print(type(X))
>>> print(type(Y))
>>> print(type(Z))

#Output
<class 'list'>
<class 'numpy.ndarray'>
<class 'tensorflow.python.framework.ops.Tensor'>
```

好吧，他们的类型打印正确。但是，与其他类型相比，我们正式处理张量的更方便的函数是`tf.convert_to_tensor()`函数如下：

```py
t1 = tf.convert_to_tensor(X, dtype=tf.float32)
t2 = tf.convert_to_tensor(Z, dtype=tf.float32)
```

现在让我们使用以下代码查看它们的类型：

```py
>>> print(type(t1))
>>> print(type(t2))

#Output:
<class 'tensorflow.python.framework.ops.Tensor'>
<class 'tensorflow.python.framework.ops.Tensor'>
```

太棒了！关于张量的讨论已经足够了。因此，我们可以考虑以术语秩为特征的结构。

## 秩和形状

称为秩的维度单位描述每个张量。它识别张量的维数。因此，秩被称为张量的阶数或维度。阶数零张量是标量，阶数 1 张量是向量，阶数 2 张量是矩阵。

以下代码定义了 TensorFlow `scalar`，`vector`，`matrix`和`cube_matrix`。在下一个示例中，我们将展示秩如何工作：

```py
import tensorflow as tf
scalar = tf.constant(100)
vector = tf.constant([1,2,3,4,5])
matrix = tf.constant([[1,2,3],[4,5,6]])

cube_matrix = tf.constant([[[1],[2],[3]],[[4],[5],[6]],[[7],[8],[9]]])

print(scalar.get_shape())
print(vector.get_shape())
print(matrix.get_shape())
print(cube_matrix.get_shape())
```

结果打印在这里：

```py
>>>
()
(5,)
(2, 3)
(3, 3, 1)
>>>

```

张量的形状是它具有的行数和列数。现在我们将看看如何将张量的形状与其阶数联系起来：

```py
>>scalar.get_shape()
TensorShape([])

>>vector.get_shape()
TensorShape([Dimension(5)])

>>matrix.get_shape()
TensorShape([Dimension(2), Dimension(3)])

>>cube.get_shape()
TensorShape([Dimension(3), Dimension(3), Dimension(1)])

```

## 数据类型

除了阶数和形状，张量具有数据类型。以下是数据类型列表：

| 数据类型 | Python 类型 | 描述 |
| --- | --- | --- |
| `DT_FLOAT` | `tf.float32` | 32 位浮点 |
| `DT_DOUBLE` | `tf.float64` | 64 位浮点 |
| `DT_INT8` | `tf.int8` | 8 位有符号整数 |
| `DT_INT16` | `tf.int16` | 16 位有符号整数 |
| `DT_INT32` | `tf.int32` | 32 位有符号整数 |
| `DT_INT64` | `tf.int64` | 64 位有符号整数 |
| `DT_UINT8` | `tf.uint8` | 8 位无符号整数 |
| `DT_STRING` | `tf.string` | 可变长度字节数组。张量的每个元素都是一个字节数组 |
| `DT_BOOL` | `tf.bool` | 布尔 |
| `DT_COMPLEX64` | `tf.complex64` | 复数由两个 32 位浮点组成：实部和虚部 |
| `DT_COMPLEX128` | `tf.complex128` | 复数由两个 64 位浮点组成：实部和虚部 |
| `DT_QINT8` | `tf.qint8` | 量化 Ops 中使用的 8 位有符号整数 |
| `DT_QINT32` | `tf.qint32` | 量化 Ops 中使用的 32 位有符号整数 |
| `DT_QUINT8` | `tf.quint8` | 量化 Ops 中使用的 8 位无符号整数 |

上表是不言自明的，因此我们没有提供有关数据类型的详细讨论。 TensorFlow API 用于管理与 NumPy 数组之间的数据。

因此，要构建具有常量值的张量，将 NumPy 数组传递给`tf.constant()`运算符，结果将是具有该值的张量：

```py
import tensorflow as tf

import numpy as np
array_1d = np.array([1,2,3,4,5,6,7,8,9,10])
tensor_1d = tf.constant(array_1d)

with tf.Session() as sess:
    print(tensor_1d.get_shape())
    print(sess.run(tensor_1d))
```

运行该示例，我们获得以下内容：

```py
>>>
 (10,)
 [ 1  2  3  4  5  6  7  8  9 10]

```

要构建具有变量值的张量，请使用 NumPy 数组并将其传递给`tf.Variable`构造函数。结果将是具有该初始值的变量张量：

```py
import tensorflow as tf
import numpy as np

# Create a sample NumPy array
array_2d = np.array([(1,2,3),(4,5,6),(7,8,9)])

# Now pass the preceding array to tf.Variable()
tensor_2d = tf.Variable(array_2d)

# Execute the preceding op under an active session
with tf.Session() as sess:
    sess.run(tf.global_variables_initializer())
    print(tensor_2d.get_shape())
    print sess.run(tensor_2d)
# Finally, close the TensorFlow session when you're done
sess.close()
```

在前面的代码块中，`tf.global_variables_initializer()`用于初始化我们之前创建的所有操作。如果需要创建一个初始值取决于另一个变量的变量，请使用另一个变量的`initialized_value()`。这可确保以正确的顺序初始化变量。

结果如下：

```py
>>>
 (3, 3)
 [[1 2 3]
 [4 5 6]
 [7 8 9]]

```

为了便于在交互式 Python 环境中使用，我们可以使用`InteractiveSession`类，然后将该会话用于所有`Tensor.eval()`和`Operation.run()`调用：

```py
import tensorflow as tf # Import TensorFlow
import numpy as np # Import numpy

# Create an interactive TensorFlow session
interactive_session = tf.InteractiveSession()

# Create a 1d NumPy array 
array1 = np.array([1,2,3,4,5]) # An array

# Then convert the preceding array into a tensor
tensor = tf.constant(array1) # convert to tensor
print(tensor.eval()) # evaluate the tensor op

interactive_session.close() # close the session
```

### 提示

`tf.InteractiveSession()`只是方便的语法糖，用于在 IPython 中保持默认会话打开。

结果如下：

```py
>>>
   [1 2 3 4 5]

```

在交互式设置中，例如 shell 或 IPython Notebook，这可能会更容易，因为在任何地方传递会话对象都很繁琐。

### 注意

IPython 笔记本现在称为 Jupyter 笔记本。它是一个交互式计算环境，您可以在其中组合代码执行，富文本，数学，绘图和富媒体。有关更多信息，感兴趣的读者请参阅[此链接](https://ipython.org/notebook.html)。

定义张量的另一种方法是使用`tf.convert_to_tensor`语句：

```py
import tensorflow as tf
import numpy as np
tensor_3d = np.array([[[0, 1, 2], [3, 4, 5], [6, 7, 8]],
                      [[9, 10, 11], [12, 13, 14], [15, 16, 17]],
                      [[18, 19, 20], [21, 22, 23], [24, 25, 26]]])
tensor_3d = tf.convert_to_tensor(tensor_3d, dtype=tf.float64)

with tf.Session() as sess:
    print(tensor_3d.get_shape())
    print(sess.run(tensor_3d))
# Finally, close the TensorFlow session when you're done
sess.close()
```

以下是上述代码的输出：

```py
>>>
(3, 3, 3)
[[[  0\.   1\.   2.]
  [  3\.   4\.   5.]
  [  6\.   7\.   8.]]
 [[  9\.  10\.  11.]
  [ 12\.  13\.  14.]
  [ 15\.  16\.  17.]]
 [[ 18\.  19\.  20.]
  [ 21\.  22\.  23.]
  [ 24\.  25\.  26.]]]

```

## 变量

变量是用于保存和更新参数的  TensorFlow 对象。必须初始化变量，以便您可以保存并恢复它以便稍后分析代码。使用`tf.Variable()`或`tf.get_variable()`语句创建变量。而`tf.get_varaiable()`被推荐但`tf.Variable()`是低标签抽象。

在下面的示例中，我们要计算从 1 到 10 的数字，但让我们先导入 TensorFlow：

```py
import tensorflow as tf
```

我们创建了一个将初始化为标量值 0 的变量：

```py
value = tf.get_variable("value", shape=[], dtype=tf.int32, initializer=None, regularizer=None, trainable=True, collections=None)
```

`assign()`和`add()`运算符只是计算图的节点，因此在会话运行之前它们不会执行赋值：

```py
one = tf.constant(1)
update_value = tf.assign_add(value, one)
initialize_var = tf.global_variables_initializer()
```

我们可以实例化计算图：

```py
with tf.Session() as sess:
    sess.run(initialize_var)
    print(sess.run(value))
    for _ in range(5):
        sess.run(update_value)
        print(sess.run(value))
# Close the session
```

让我们回想一下，张量对象是操作结果的符号句柄，但它实际上并不保存操作输出的值：

```py
>>>
0
1
2
3
4
5

```

## 获取

要获取操作的输出，可以通过调用会话对象上的`run()`并传入张量来执行图。除了获取单个张量节点，您还可以获取多个张量。

在下面的示例中，使用`run()`调用一起提取 sum 和 multiply 张量：

```py
import tensorflow as tf
constant_A = tf.constant([100.0])
constant_B = tf.constant([300.0])
constant_C = tf.constant([3.0])

sum_ = tf.add(constant_A,constant_B)
mul_ = tf.multiply(constant_A,constant_C)

with tf.Session() as sess:
    result = sess.run([sum_,mul_])# _ means throw away afterwards
    print(result)
```

输出如下：

```py
>>>
[array(400.],dtype=float32),array([ 300.],dtype=float32)]

```

应该注意的是，所有需要执行的操作（即，为了产生张量值）都运行一次（每个请求的张量不是一次）。

## 馈送和占位符

有四种方法将数据输入 TensorFlow 程序（更多信息，请参阅[此链接](https://www.tensorflow.org/api_guides/python/reading_data)）：

*   数据集 API：这使您能够从简单和可重用的分布式文件系统构建复杂的输入管道，并执行复杂的操作。如果您要处理不同数据格式的大量数据，建议使用数据集 API。数据集 API 为 TensorFlow 引入了两个新的抽象，用于创建可馈送数据集：`tf.contrib.data.Dataset`（通过创建源或应用转换操作）和`tf.contrib.data.Iterator`。
*   馈送：这允许我们将数据注入计算图中的任何张量。
*   从文件中读取：这允许我们使用 Python 的内置机制开发输入管道，用于从图开头的数据文件中读取数据。
*   预加载数据：对于小数据集，我们可以使用 TensorFlow 图中的常量或变量来保存所有数据。

在本节中，我们将看到馈送机制的例子。我们将在接下来的章节中看到其他方法。 TensorFlow 提供了一种馈送机制，允许我们将数据注入计算图中的任何张量。您可以通过`feed_dict`参数将源数据提供给启动计算的`run()`或`eval()`调用。

### 提示

使用`feed_dict`参数进行馈送是将数据提供到 TensorFlow 执行图中的最低效方法，并且仅应用于需要小数据集的小型实验。它也可以用于调试。

我们还可以用 Feed 数据（即变量和常量）替换任何张量。最佳做法是使用[`tf.placeholder()`](https://www.tensorflow.org/api_docs/python/tf/placeholder)使用 TensorFlow 占位符节点。占位符专门用作 Feed 的目标。空占位符未初始化，因此不包含任何数据。

因此，如果在没有 Feed 的情况下执行它，它将始终生成错误，因此您不会忘记提供它。以下示例显示如何提供数据以构建随机 2×3 矩阵：

```py
import tensorflow as tf
import numpy as np

a = 3
b = 2
x = tf.placeholder(tf.float32,shape=(a,b))
y = tf.add(x,x)

data = np.random.rand(a,b)
sess = tf.Session()
print(sess.run(y,feed_dict={x:data}))

sess.close()# close the session
```

输出如下：

```py
>>>
[[ 1.78602004  1.64606333]
 [ 1.03966308  0.99269408]
 [ 0.98822606  1.50157797]]
>>>

```