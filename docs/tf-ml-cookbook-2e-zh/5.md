# 使用矩阵

了解 TensorFlow 如何与矩阵一起工作对于通过计算图来理解数据流非常重要。

> 值得强调的是矩阵在机器学习（以及一般数学）中的重要性。大多数机器学习算法在计算上表示为矩阵运算。本书未涉及矩阵属性和矩阵代数（线性代数）的数学背景，因此强烈建议读者充分了解矩阵以适应矩阵代数。

## 做好准备

许多算法依赖于矩阵运算。 TensorFlow 为我们提供了易于使用的操作来执行此类矩阵计算。对于以下所有示例，我们首先通过运行以下代码来创建图会话：

```py
import tensorflow as tf 
sess = tf.Session() 
```

## 操作步骤

我们将按如下方式处理秘籍：

1.  创建矩阵：我们可以从 NumPy 数组或嵌套列表创建二维矩阵，正如我们在创建和使用张量秘籍中所描述的那样。我们还可以使用张量创建函数并为`zeros()`，`ones()`，`truncated_normal()`等函数指定二维形状。 TensorFlow 还允许我们使用`diag()`函数从一维数组或列表创建对角矩阵，如下所示：

```py
identity_matrix = tf.diag([1.0, 1.0, 1.0]) 
A = tf.truncated_normal([2, 3]) 
B = tf.fill([2,3], 5.0) 
C = tf.random_uniform([3,2]) 
D = tf.convert_to_tensor(np.array([[1., 2., 3.],[-3., -7., -1.],[0., 5., -2.]])) 
print(sess.run(identity_matrix)) 
[[ 1\.  0\.  0.] 
 [ 0\.  1\.  0.] 
 [ 0\.  0\.  1.]] 
print(sess.run(A)) 
[[ 0.96751703  0.11397751 -0.3438891 ] 
 [-0.10132604 -0.8432678   0.29810596]] 
print(sess.run(B)) 
[[ 5\.  5\.  5.] 
 [ 5\.  5\.  5.]] 
print(sess.run(C)) 
[[ 0.33184157  0.08907614] 
 [ 0.53189191  0.67605299] 
 [ 0.95889051 0.67061249]] 
print(sess.run(D)) 
[[ 1\.  2\.  3.] 
 [-3\. -7\. -1.] 
 [ 0\.  5\. -2.]] 
```

> 请注意，如果我们再次运行`sess.run(C)`，我们将重新初始化随机变量并最终得到不同的随机值。

1.  加法，减法和乘法：要添加，减去或相乘相同维度的矩阵，TensorFlow 使用以下函数：

```py
print(sess.run(A+B)) 
[[ 4.61596632  5.39771316  4.4325695 ] 
 [ 3.26702736  5.14477345  4.98265553]] 
print(sess.run(B-B)) 
[[ 0\.  0\.  0.] 
 [ 0\.  0\.  0.]] 
Multiplication 
print(sess.run(tf.matmul(B, identity_matrix))) 
[[ 5\.  5\.  5.] 
 [ 5\.  5\.  5.]] 
```

值得注意的是，`matmul()`函数具有参数，用于指定是否在乘法之前转置参数或每个矩阵是否稀疏。

> 请注意，未明确定义矩阵除法。虽然许多人将矩阵划分定义为乘以逆，但与实数除法相比，它基本上是不同的。

1.  转置：转置矩阵（翻转列和行），如下所示：

```py
print(sess.run(tf.transpose(C))) 
[[ 0.67124544  0.26766731  0.99068872] 
 [ 0.25006068  0.86560275  0.58411312]] 
```

同样，值得一提的是，重新初始化为我们提供了与以前不同的价值观。

1.  行列式：要计算行列式，请使用以下内容：

```py
print(sess.run(tf.matrix_determinant(D))) 
-38.0 
```

1.  反向：要查找方阵的倒数，请参阅以下内容：

```py
print(sess.run(tf.matrix_inverse(D))) 
[[-0.5        -0.5        -0.5       ] 
 [ 0.15789474  0.05263158  0.21052632] 
 [ 0.39473684  0.13157895  0.02631579]] 
```

> 只有当矩阵是对称正定时，逆方法才基于 Cholesky 分解。如果矩阵不是对称正定，那么它基于 LU 分解。

1.  分解：对于 Cholesky 分解，请使用以下内容：

```py
print(sess.run(tf.cholesky(identity_matrix))) 
[[ 1\.  0\.  1.] 
 [ 0\.  1\.  0.] 
 [ 0\.  0\.  1.]] 
```

1.  特征值和特征向量：对于特征值和特征向量，请使用以下代码：

```py
print(sess.run(tf.self_adjoint_eig(D)) 
[[-10.65907521  -0.22750691   2.88658212] 
 [  0.21749542   0.63250104  -0.74339638] 
 [  0.84526515   0.2587998    0.46749277] 
 [ -0.4880805    0.73004459   0.47834331]] 
```

注意，`self_adjoint_eig()`函数输出第一行中的特征值和剩余向量中的后续向量。在数学中，这被称为矩阵的特征分解。

## 工作原理

TensorFlow 为我们提供了开始使用数值计算并将这些计算添加到图中的所有工具。对于简单的矩阵运算，这种表示法可能看起来很重。请记住，我们正在将这些操作添加到图中，并告诉 TensorFlow 哪些张量运行这些操作。虽然现在看起来似乎很冗长，但它有助于我们理解后面章节中的符号，这种计算方式将使我们更容易实现目标。