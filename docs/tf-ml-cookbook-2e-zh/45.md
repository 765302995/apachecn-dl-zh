# 介绍

神经网络目前在诸如图像和语音识别，阅读手写，理解文本，图像分割，对话系统，自动驾驶汽车等任务中打破记录。虽然这些上述任务中的一些将在后面的章节中介绍，但重要的是将神经网络作为一种易于实现的机器学习算法引入，以便我们以后可以对其进行扩展。

神经网络的概念已经存在了几十年。然而，它最近才获得牵引力，因为我们现在具有训练大型网络的计算能力，因为处理能力，算法效率和数据大小的进步。

神经网络基本上是应用于输入数据矩阵的一系列操作。这些操作通常是加法和乘法的集合，然后是非线性函数的应用。我们已经看到的一个例子是逻辑回归，我们在第 3 章，线性回归中看到了这一点。逻辑回归是部分斜率 - 特征乘积的总和，其后是应用 S 形函数，这是非线性的。神经网络通过允许操作和非线性函数的任意组合（包括绝对值，最大值，最小值等的应用）来进一步概括这一点。

神经网络的重要技巧称为反向传播。反向传播是一种允许我们根据学习率和损失函数输出更新模型变量的过程。我们使用反向传播来更新第 3 章，线性回归和第 4 章，支持向量机中的模型变量。

关于神经网络的另一个重要特征是非线性激活函数。由于大多数神经网络只是加法和乘法运算的组合，因此它们无法对非线性数据集进行建模。为了解决这个问题，我们在神经网络中使用了非线性激活函数。这将允许神经网络适应大多数非线性情况。

重要的是要记住，正如我们在许多算法中所看到的，神经网络对我们选择的超参数敏感。在本章中，我们将探讨不同学习率，损失函数和优化程序的影响。

> 学习神经网络的资源更多，更深入，更详细地涵盖了该主题。这些资源如下：

*   [描述反向传播的开创性论文是 Yann LeCun 等人的 Efficient Back Prop](http://yann.lecun.com/exdb/publis/pdf/lecun-98b.pdf)
*   [CS231，用于视觉识别的卷积神经网络，由斯坦福大学提供。](http://cs231n.stanford.edu/)
*   [CS224d，斯坦福大学自然语言处理的深度学习。](http://cs224d.stanford.edu/)
*   [深度学习，麻省理工学院出版社出版的一本书，Goodfellow 等人，2016]http://www.deeplearningbook.org)。

*   迈克尔·尼尔森（Michael Nielsen）有一本名为[“神经网络与深度学习”](http://neuralnetworksanddeeplearning.com/)的在线书籍。
*   对于一个更实用的方法和神经网络的介绍，Andrej Karpathy 用 JavaScript 实例写了一个很棒的总结，称为[黑客的神经网络指南](http://karpathy.github.io/neuralnets/)。
*   另一个总结深度学习的网站被 Ian Goodfellow，Yoshua Bengio 和 Aaron Courville 称为[初学者深度学习](http://randomekek.github.io/deep/deeplearning.html)。