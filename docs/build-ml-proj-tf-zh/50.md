# 残差网络（ResNet）

残差网络架构于 2015 年 12 月出现（与 Inception V3 几乎同时出现），它带来了一个简单而新颖的想法：不仅使用每个构成层的输出，还将该层的输出与原始输入结合。

在下图中，我们观察到 ResNet 模块之一的简化​​视图。 它清楚地显示了卷积层堆栈末尾的求和运算，以及最终的 relu 运算：

![Residual Networks (ResNet)](img/00132.jpg)

ResNet 一般架构

模块的卷积部分包括将特征从 256 个值减少到 64 个值，一个保留特征数的 3x3 过滤层以及一个从 64 x 256 个值增加 1x1 层的特征。 在最近的发展中，ResNet 的使用深度还不到 30 层，分布广泛。

## 其他深度神经网络架构

最近开发了很多神经网络架构。 实际上，这个领域是如此活跃，以至于我们每年或多或少都有新的杰出建筑外观。 最有前途的神经网络架构的列表是：

*   SqueezeNet：此架构旨在减少 Alexnet 的参数数量和复杂性，声称减少了 50 倍的参数数量
*   高效神经网络（Enet）：旨在构建更简单，低延迟的浮点运算数量，具有实时结果的神经网络
*   Fractalnet：它的主要特征是非常深的网络的实现，不需要残留的架构，将结构布局组织为截断的分形