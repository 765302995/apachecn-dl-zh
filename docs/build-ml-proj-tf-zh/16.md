# 成本函数的确定

与所有机器学习技术一样，我们必须确定一个误差函数，我们需要将其最小化，这表明解决问题的适当性。

用于线性回归的最常用的`cost`函数称为最小二乘。

## 最小二乘

为了计算函数的最小二乘误差，我们通常会寻找一种测量点与建模线的接近程度的方法。 因此，我们定义了一个函数，用于测量每个元组`x[n]`和`y[n]`与建模线的对应值之间的距离。

对于 2D 回归，我们有一个数字元组`(X[0],Y[0]),(X[1],Y[1])...(X[n],Y[n])`的列表，通过最小化以下函数，可以找到`β[0]`和`β[1]`的值：

![Least squares](img/00042.jpg)

简单来说，求和代表预测值与实际值之间的欧几里得距离之和。

进行运算的原因是，平方误差的总和为我们提供了一个唯一且简单的全局数，预期数与实数之差为我们提供了适当的距离，平方幂为我们提供了一个正数，这会惩罚一个整数。 多于线性的时尚。