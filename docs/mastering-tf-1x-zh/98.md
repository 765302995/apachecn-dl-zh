# 二分类的逻辑回归

对于二分类，我们将模型函数`φ(z)`定义为 sigmoid 函数，如下所示：

![](img/62e26ec4-6cff-4601-b544-cb79aa11a704.png)

sigmoid 函数在范围[0,1]之间产生 y 的值。因此，我们可以使用`y = φ(z)`的值来预测类：如果`y > 0.5`则 class 等于 1，否则 class 等于 0。

正如我们在本章的前几节中所见，对于线性回归，可以通过查找最小化损失函数的参数来训练模型，并且损失函数可以是平方误差或均方误差的总和。对于逻辑回归，我们希望最大化可能性：`L(w) = P(y|x, w, b)`。

但是，由于更容易使对数似然最大化，因此我们使用对数似然`l(w)`作为成本函数。因此，损失函数（`J(w)`）被写为 `-1(w)`，其可以使用诸如梯度下降的优化算法来最小化。

二元逻辑回归的损失函数在数学上写成如下：

![](img/43249834-ffa5-490f-842b-3be538ea34e8.png)

其中`φ(z)`是 S 形函数。

我们将在下一节中实现这个损失函数。