# 正则化回归

在线性回归中，我们训练的模型返回训练数据的最佳拟合参数。但是，在训练数据上找到最合适的参数可能会导致过拟合。

**过拟合**意味着模型最适合训练数据，但会给测试数据带来更大的误差。因此，我们通常在模型中添加惩罚项以获得更简单的模型。

该惩罚项称为**正则化**项，由此获得的回归模型称为正则化回归模型。正则化模型有三种主要类型：

*   **套索回归**：在套索正则化中，也称为 L1 正则化，正则化项是套索参数`α`乘以权重`w`绝对值之和。因此，损失函数如下：

![](img/662a9855-a00c-41ad-8b0e-2b65dbfbdd69.png)

*   **岭回归**：在脊正则化中，也称为 L2 正则化，正则化项是脊参数`α`乘以`i-th`权重`w`的平方和。因此，损失函数如下：

![](img/b6aba15b-577d-4a22-a559-bd6f1f2e0d1b.png)

*   **ElasticNet 回归**：当我们添加套索和脊正则化项时，得到的正则化称为 ElasticNet 正则化。因此，损失函数如下：

![](img/f6144fe6-9175-4d26-9e6b-f07fb0cd3212.png)

有关正则化的更多详细信息，[请参阅互联网上的这些资源](http://www.statisticshowto.com/regularization/)。

一个简单的经验法则是当我们想要删除某些特征时使用 L1 或 Lasso，从而减少计算时间，但代价是降低了准确性。

现在让我们看看在 TensorFlow 中实现的这些正则化损失函数。我们将继续使用前面示例中使用的 Boston 数据集。