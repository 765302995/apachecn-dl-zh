# 再训练或微调模型

在像 ImageNet 这样的大型和多样化数据集上训练的模型能够检测和捕获一些通用特征，如曲线，边缘和形状。其中一些特征很容易适用于其他类型的数据集。因此，在迁移学习中，我们采用这样的通用模型，并使用以下一些技术来微调或再训练它们到我们的数据集：

*   **废除并替换最后一层：** m 通常的做法是删除最后一层并添加与我们的数据集匹配的新分类层。例如，ImageNet 模型使用 1,000 个类别进行训练，但我们的 COCO 动物数据集只有 8 个类别，因此我们删除了 softmax 层，该层使用 softmax 层生成 1,000 个类别的概率，该层生成 8 个类别的概率。通常，当新数据集几乎与训练模型的数据集类似时使用此技术，因此仅需要再训练最后一层。
*   **冻结前几层**：另一种常见做法是冻结前几层，以便仅使用新数据集更新最后未冻结层的权重。我们将看到一个例子，我们冻结前 15 层，同时只再训练最后 10 层。通常，当新数据集与训练模型的数据集非常不相似时使用此技术，因此不仅需要训练最后的层。
*   **调整超参数**：您还可以在再训练之前调整超参数，例如更改学习率或尝试不同的损失函数或不同的优化器。

TensorFlow 和 Keras 均提供预训练模型。

我们将在文件夹`tensorflow/models/research/slim/nets`中通过 TensorFlow Slim 演示我们的示例，TensorFlow Slim 在编写时有几个预训练的模型。我们将使用 TensorFlow Slim 来实例化预训练的模型，然后从下载的检查点文件加载权重。然后，加载的模型将用于使用新数据集进行预测。然后我们将再训练模型以微调预测。

我们还将通过`keras.applications`模块中提供的 Keras 预训练模型演示迁移学习。虽然 TensorFlow 有大约 20 多个预训练模型，但`keras.appplications`只有以下 7 种预训练模型：

*   [Xception](https://keras.io/applications/#xception)

*   [VGG16](https://keras.io/applications/#vgg16)

*   [VGG19](https://keras.io/applications/#vgg19)

*   [ResNet50](https://keras.io/applications/#resnet50)

*   [InceptionV3](https://keras.io/applications/#inceptionv3)

*   [InceptionResNetV2](https://keras.io/applications/#inceptionresnetv2)

*   [MobileNet](https://keras.io/applications/#mobilenet)