# TensorFlow Lite

在编写本书时，TF Lite 是该版块中的新手，并且仍处于开发人员视图中。 TF Lite 是 TensorFlow Mobile 和 TensorFlow 的一个非常小的子集，因此使用 TF Lite 编译的二进制文件非常小，并提供卓越的表现。除了减小二进制文件的大小，TensorFlow 还采用了各种其他技术，例如：

*   内核针对各种设备和移动架构进行了优化
*   计算中使用的值是量化的
*   激活函数是预融合的
*   它利用设备上可用的专用机器学习软件或硬件，例如 Android NN API

在 TF Lite 中使用模型的工作流程如下：

1.  **获取模型：**您可以训练自己的模型或选择可从不同来源获得的预训练模型，并按原样使用预训练或使用您自己的数据再训练，或在修改某些部分后再训练该模型。只要您在文件中使用扩展名为.pb 或.pbtxt 的训练模型，就可以继续执行下一步。我们在前面的章节中学习了如何保存模型。
2.  **检查模型**：模型文件只包含图的结构，因此需要保存检查点文件。检查点文件包含模型的序列化变量，例如权重和偏差。我们在前面的章节中学习了如何保存检查点。
3.  **冻结模型**：合并检查点和模型文件，也称为冻结图。 TensorFlow 为此步骤提供`freeze_graph`工具，可以按如下方式执行：

```py
$ freeze_graph
 --input_graph=mymodel.pb
 --input_checkpoint=mycheckpoint.ckpt
 --input_binary=true
 --output_graph=frozen_model.pb
 --output_node_name=mymodel_nodes
```

1.  **转换模型**：需要使用 TensorFlow 提供的`toco`工具将步骤 3 中的冻结模型转换为 TF Lite 格式：

```py
$ toco 
 --input_file=frozen_model.pb
 --input_format=TENSORFLOW_GRAPHDEF
 --output_format=TFLITE
 --input_type=FLOAT
 --input_arrays=input_nodes
 --output_arrays=mymodel_nodes
 --input_shapes=n,h,w,c
```

1.  现在，在步骤 4 中保存的`.tflite`模型可以在使用 TFLite 二进制文件进行推理的 Android 或 iOS 应用中使用。在您的应用中包含 TFLite 二进制文件的过程不断发展，因此我们建议读者按照[此链接中的信息](https://github.com/tensorflow/tensorflow/tree/master/tensorflow/contrib/lite/g3doc)在您的 Android 或 iOS 应用中包含 TFLite 二进制文件。

通常，您可以使用`graph_transforms:summarize_graph`工具修剪在步骤 1 中获得的模型。 修剪后的模型将仅具有在推理或预测时从输入到输出的路径。仅删除训练或调试所需的任何其他节点和路径（例如保存检查点），从而使最终模型的大小非常小。

官方 TensorFlow 仓库附带 TF Lite 演示，该演示使用预训练的`mobilenet`对来自 1001 类别中的设备相机的输入进行分类。演示应用显示前三个类别的概率。