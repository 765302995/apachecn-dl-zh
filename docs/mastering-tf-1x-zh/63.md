# Keras 核心层

Keras 核心层实现基本操作，几乎用于各种网络架构。下表给出了 Keras 2 提供的层的摘要和说明：

| **层名称** | **描述** |
| --- | --- |
| `Dense` | 这是一个简单的完全连接的神经网络层。该层生成以下函数的输出：`激活(输入 x 权重 + 偏差)`，其中激活是指传递给层的激活函数，默认为`None`。 |
| `Activation` | 该层将指定的激活函数应用于输出。该层生成以下函数的输出：**`激活(输入)`，其中激活是指传递给该层的激活函数。以下激活函数可用于实例化层：`softmax`，  `elu`，  `selu`，  `softplus`，  `softsign`，  `relu`，  `tanh`，  `sigmoid`，  `hard_sigmoid`和`linear` |
| `Dropout` | 该层以指定的 dropout 率将 dropout 正则化应用于输入。 |
| `Flatten` | 该层使输入变平，即对于三维输入，它变平并产生一维输出。 |
| `Reshape` | 此层将输入转换为指定的形状。 |
| `Permute` | 此层按照指定的模式重新排序输入尺寸。 |
| `RepeatVector` | 该层以给定次数重复输入。因此，如果输入是 2D 张量的形状（#samples，＃feature）并且该层被赋予`n`次重复，那么输出将是 3D 张量的形状（#samples，n， ＃特征）。 |
| `Lambda` | 该层将提供的函数包装为层。因此，输入通过提供的自定义函数传递以产生输出。该层为 Keras 用户提供了最终的可扩展性，可以将自己的自定义函数添加为层。 |
| `ActivityRegularization` | 该层将 L1 或 L2 或两种正则化的组合应用于其输入。该层应用于激活层的输出或具有激活函数的层的输出。 |
| `Masking` | 此层在输入张量中屏蔽或跳过这些时间步长，其中输入张量中的所有值都等于作为层参数提供的屏蔽值。 |