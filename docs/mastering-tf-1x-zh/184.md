# 在 Docker 容器中提供模型

要在容器中提供模型，说明如下：

1.  启动上一节中构建的 MNIST 容器：

```py
$ docker run --name=mnist_container -it $USER/mnist_serving
```

1.  将`cd`命令转到主文件夹。
2.  使用以下命令运行 ModelServer：

```py
$ tensorflow_model_server  --model_name=mnist --model_base_path=/tmp/mnist_model/ &> mnist_log &
```

1.  使用示例客户端检查模型中的预测：

```py
$ python serving/tensorflow_serving/example/mnist_client.py --num_tests=100 --server=localhost:8500
```

1.  我们看到错误率为 7%，就像我们之前的笔记本示例执行一样：

```py
Extracting /tmp/train-images-idx3-ubyte.gz
Extracting /tmp/train-labels-idx1-ubyte.gz
Extracting /tmp/t10k-images-idx3-ubyte.gz
Extracting /tmp/t10k-labels-idx1-ubyte.gz
....................................................................................................
Inference error rate: 7.0%
```

而已！您已经构建了 Docker 镜像，并在 Docker 镜像中为您的模型提供服务。发出`exit`命令退出容器。